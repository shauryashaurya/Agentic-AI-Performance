# Setup / Intro

## 1. Objectives

1. Verify the local Python environment can create directories, write JSONL logs, and record stable timestamps.
2. Establish minimal utilities (timer, IDs, randomness, JSONL writer) that later sections reuse.
3. Produce a first artifact in `data/raw_events/` to validate file paths and I/O permissions.

## 2. What this script does

1. Creates `data/`, `data/raw_events/`, and `data/derived/` if they do not exist.
2. Defines utilities:

   * `Timer` for elapsed-time measurement using a monotonic clock.
   * `new_run_id()` for UUID4 run identifiers.
   * `now_iso()` for UTC ISO-8601 timestamps without `utcnow()` deprecation.
   * `random_seed(seed)` to force deterministic pseudo-randomness when desired.
   * `jitter(p)` to simulate nondeterministic outcomes.
   * `write_jsonl(path, records)` to append events safely.
3. Runs a “smoke test” that:

   * Seeds randomness (`123` by default).
   * Collects 10 Bernoulli samples from `jitter(0.7)` with short sleeps.
   * Writes a single JSON record to `data/raw_events/00_smoke.jsonl`.
   * Prints elapsed time and empirical success rate of the samples.

## 3. Why this matters for LLMOps

1. Later analysis relies on **timestamps**, **IDs**, and **append-only** event streams; this script is the minimal proof those fundamentals work on your machine.
2. **JSON Lines** is the simplest transport between producers (agents) and consumers (analytics). If this file is written, you can scale up without changing formats.
3. A **monotonic timer** is required for accurate latency measurement; this prevents negative or skewed durations if the system clock adjusts.

## 4. Environment and dependencies

1. Python 3.10+ recommended.
2. No external packages required for this script.
3. Works on CPU-only laptops; GPU is irrelevant here.
4. File-system permissions must allow creating `data/` under the project root.

## 5. Directory layout verified by the script

1. `data/` — top-level data directory.
2. `data/raw_events/` — append-only JSONL event files from generators.
3. `data/derived/` — normalized Parquet/CSV and plots created by later sections.

## 6. Detailed walkthrough of components

1. **Path setup**

   * `BASE = Path(__file__).resolve().parent`
   * `DATA = BASE / "data"`, `RAW = DATA / "raw_events"`, `DERIVED = DATA / "derived"`
   * `mkdir(parents=True, exist_ok=True)` ensures idempotent directory creation.

2. **Timekeeping**

   * `Timer` uses `time.perf_counter()` to measure durations in seconds.
   * `now_iso()` uses `datetime.now(timezone.utc).isoformat()` to avoid `datetime.utcnow()` deprecation; add `.replace("+00:00", "Z")` if you require `Z`.

3. **Identity**

   * `new_run_id()` returns `uuid.uuid4()` as a string.
   * Unique IDs enable correlation across events and later joins.

4. **Randomness**

   * `random_seed(seed)` sets deterministic PRNG state.
   * `jitter(p)` returns `True` with probability `p` (default 0.5). Used to simulate non-deterministic success/failure.

5. **Logging**

   * `write_jsonl(path, records)` appends each dict as one JSON object per line.
   * Append-only behavior avoids partial-line corruption on crash.

6. **Smoke test flow**

   * Create `run_id`.
   * Loop 10 times:

     * `ok = jitter(0.7)` to simulate an outcome.
     * `time.sleep(0.01)` to emulate minimal latency.
   * Compute elapsed seconds from `Timer`.
   * Write one record to `data/raw_events/00_smoke.jsonl` with fields:

     * `run_id` (uuid4)
     * `ts` (UTC ISO-8601)
     * `elapsed_s` (float seconds)
     * `samples` (list of `{i, ok}` pairs)

## 7. Event shape produced

1. File: `data/raw_events/00_smoke.jsonl`
2. Exactly one line appended per script execution.
3. Record fields:

   * `run_id: string`
   * `ts: string (ISO-8601, UTC)`
   * `elapsed_s: float`
   * `samples: list[{"i": int, "ok": bool}]`
4. Example (one line):

   ```
   {"run_id":"<uuid>","ts":"2025-08-09T10:12:34+00:00","elapsed_s":0.1234,"samples":[{"i":0,"ok":true},...,{"i":9,"ok":false}]}
   ```

## 8. How to run and validate

1. Run:

   * `python 00_setup_and_smoke_test.py`
2. Expected stdout:

   * Path confirmation, elapsed seconds, and `ok_rate` close to 0.7.
3. Validate file output:

   * `ls -l data/raw_events/00_smoke.jsonl`
   * `tail -n 1 data/raw_events/00_smoke.jsonl`
4. Quick integrity checks:

   * Line is valid JSON.
   * `samples` length is 10.
   * `0.0 <= elapsed_s < 1.0` (approximate; depends on machine speed).

## 9. Reproducibility controls

1. Change `random_seed(123)` to a fixed integer for repeatable outcomes.
2. Rerun with different seeds when you want distribution diversity across smoke runs.
3. Keep `sleep` small to make runs fast; adjust for stress tests as needed.

## 10. Common failure modes and fixes

1. **PermissionError** writing to `data/`

   * Cause: project directory not writable.
   * Fix: run from a writable path or adjust directory permissions.
2. **UnicodeEncodeError** on write

   * Cause: non-UTF8 locale settings.
   * Fix: ensure `encoding="utf-8"` remains in file writes and environment supports UTF-8.
3. **Clock or timezone confusion**

   * Cause: mixing local time and UTC later.
   * Fix: always store UTC (this script already does).
4. **Inconsistent randomness**

   * Cause: seed not set or changed between runs.
   * Fix: set a seed explicitly when you need reproducibility.

## 11. Performance characteristics on a laptop

1. CPU-only, minimal memory and I/O.
2. By default, writes a single JSONL line; runtime dominated by `sleep(0.01) × 10`.
3. Suitable for quick checks before heavier sections.

## 12. Security and data hygiene

1. The smoke test contains no PII or secrets.
2. If you later add `attrs` or `data`, redact sensitive keys at emission time.
3. Consider log rotation in later scripts; the smoke file is small but establishes the write pattern.

## 13. Extending this script for real projects

1. Replace `samples` with first-class **events**:

   * Add fields `kind`, `event_id`, `duration_s`, etc., to align with the later schema.
2. Emit multiple JSONL lines rather than a single record:

   * One line per event (`run_start`, step events, `run_ok`).
3. Introduce **sampling** and **log rotation**:

   * Sample rate to control volume.
   * Rotate file by size to cap local storage.

## 14. Integration with later sections

1. Section 3 expects JSONL in `data/raw_events/`; this file confirms the path and permissions.
2. You can ingest `00_smoke.jsonl` along with later logs to validate the ingestion code’s tolerance for “other” record shapes.
3. The timing and ID helpers are consistent with the rest of the workshop and can be imported or duplicated verbatim.

## 15. Checklist for completion

1. `data/raw_events/00_smoke.jsonl` exists and is non-empty.
2. One valid JSON object appended with expected fields.
3. `elapsed_s` is reasonable and positive.
4. You can re-run the script without errors and see a new line appended each time.
5. You can delete the file and re-run to recreate it without additional setup.

## 16. Variations you can try immediately

1. Increase `range(10)` to `range(1000)` to test larger writes and buffering.
2. Change `jitter(0.7)` to different probabilities (e.g., `0.2`, `0.9`) and observe `ok_rate`.
3. Add a new top-level field (e.g., `"host": platform.node()`) to test schema evolution tolerance in ingestion code.
